## Information gains by splitting a small dataset
When classifying labels in a dataset, the best way to split among their
explanatory attributes is to maximize the amount of information from it.
Entropy, from information theory, grows proportionally relative to the sum of
log-transformed probabilities of appearance for every class in a group. Simply,
the  lowest the entropy in a group, the more homogeneous it is and the more
we can know about it. 
